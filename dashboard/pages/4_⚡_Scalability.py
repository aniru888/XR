"""
Scalability Dimension
Capacity to deliver enterprise-grade solutions
"""
import streamlit as st
import sys
from pathlib import Path
import pandas as pd

# Add paths
sys.path.insert(0, str(Path(__file__).parent.parent / "config"))
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "analysis" / "common"))

from dimensions import get_dimension_by_id, COLORS
from data_loader import load_dimension
from text_analytics import WordCloudGenerator, SentimentAnalyzer, TopicModeler

# ============================================================================
# PAGE CONFIGURATION
# ============================================================================

st.set_page_config(
    page_title="Scalability | XR Dashboard",
    page_icon="‚ö°",
    layout="wide"
)

# Load dimension configuration
dimension = get_dimension_by_id('scalability')
if not dimension:
    st.error("Failed to load dimension configuration")
    st.stop()

# Load data
try:
    data = load_dimension('scalability')
    corpus = data['corpus']
    text = data['text']
    sources = data['sources']
except Exception as e:
    st.error(f"Failed to load dimension data: {e}")
    st.stop()

# ============================================================================
# DIMENSION HEADER
# ============================================================================

st.markdown(f"# {dimension.icon} {dimension.name}")

st.markdown(f"""
<div style='background: linear-gradient(135deg, {COLORS['primary_blue']} 0%, {COLORS['accent_teal']} 100%);
            color: white; padding: 20px; border-radius: 10px; margin: 20px 0;'>
    <h3 style='color: white; margin: 0;'>üìê Framework Purpose</h3>
    <p style='font-size: 1.2em; margin: 10px 0 0 0;'>{dimension.purpose}</p>
</div>
""", unsafe_allow_html=True)

st.markdown(f"""
<div style='background: #f8f9fa; padding: 15px; border-left: 5px solid {COLORS['accent_teal']};
            border-radius: 5px; margin: 20px 0;'>
    <strong>üîç Analysis Question:</strong><br/>
    {dimension.question}
</div>
""", unsafe_allow_html=True)

# ============================================================================
# KEY METRICS
# ============================================================================

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("Readiness Score", f"{dimension.readiness_score}%")
    st.caption(dimension.readiness_color)

with col2:
    st.metric("Data Entries", f"{dimension.entry_count:,}")

with col3:
    st.metric("Verified URLs", len(sources))

with col4:
    st.metric("Infrastructure Stack", "5 Layers")

# ============================================================================
# KEY FINDING
# ============================================================================

st.markdown(f"""
<div style='background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
            padding: 20px; border-radius: 10px; border-left: 5px solid {COLORS['primary_blue']};
            margin: 20px 0;'>
    <h4 style='margin: 0; color: {COLORS["primary_blue"]};'>üí° Key Finding</h4>
    <p style='font-size: 1.1em; margin: 10px 0 0 0; color: #1a1a1a;'>{dimension.key_finding}</p>
</div>
""", unsafe_allow_html=True)

# ============================================================================
# INFRASTRUCTURE BREAKDOWN
# ============================================================================

st.markdown("## üèóÔ∏è Infrastructure Stack Analysis")

st.markdown("""
Scalability of XR requires a comprehensive infrastructure stack spanning from network layer to device management:
""")

stack_data = [
    {
        "Layer": "üåê 5G/6G Network",
        "Purpose": "Low-latency wireless connectivity",
        "Key Vendors": "Nokia, Verizon, Ericsson, Qualcomm",
        "Entries": "~120"
    },
    {
        "Layer": "üñ•Ô∏è Edge Computing",
        "Purpose": "Distributed processing near users",
        "Key Vendors": "Cloudflare, Akamai, VMware",
        "Entries": "~120"
    },
    {
        "Layer": "‚òÅÔ∏è Cloud Rendering",
        "Purpose": "Remote rendering and streaming",
        "Key Vendors": "AWS, Azure, Google, NVIDIA",
        "Entries": "~120"
    },
    {
        "Layer": "üì± Device Management",
        "Purpose": "Fleet management and provisioning",
        "Key Vendors": "Microsoft Intune, Jamf, MongoDB",
        "Entries": "~120"
    },
    {
        "Layer": "üîß Infrastructure Tools",
        "Purpose": "Orchestration and deployment",
        "Key Vendors": "Kubernetes, Docker, Okta",
        "Entries": "~120"
    }
]

stack_df = pd.DataFrame(stack_data)
st.dataframe(stack_df, use_container_width=True, hide_index=True)

# ============================================================================
# TEXT ANALYTICS
# ============================================================================

st.markdown("---")
st.markdown("## üìä Text Analytics")

# Load pre-computed analytics from data files
analytics_path = dimension.get_data_paths()[0].parent  # XR scalability directory
sentiment_file = analytics_path / "XR_Sentiment_Analysis_Results.csv"
topics_file = analytics_path / "XR_LDA_Topic_Distribution.csv"

if text and len(text.strip()) > 100:

    # Word Cloud
    st.markdown("### üìä Word Cloud Analysis")
    try:
        wc_gen = WordCloudGenerator(width=1200, height=600)
        wordcloud = wc_gen.generate(text, max_words=100, colormap='inferno')

        import matplotlib.pyplot as plt
        fig, ax = plt.subplots(figsize=(15, 7))
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.axis('off')
        ax.set_title('Infrastructure Themes in XR Scalability', fontsize=16, fontweight='bold', pad=20)
        st.pyplot(fig)

        col1, col2 = st.columns([2, 1])
        with col1:
            top_words = wc_gen.get_top_words(text, n=20)
            top_df = pd.DataFrame(top_words, columns=['Word', 'Frequency'])
            st.dataframe(top_df, use_container_width=True, hide_index=True)

        with col2:
            st.markdown("**Infrastructure Focus:**")
            if top_words:
                st.markdown(f"- Core technology: **{top_words[0][0]}**")
                st.markdown("- Reveals bottlenecks")
                st.markdown("- Shows vendor priorities")
    except Exception as e:
        st.warning(f"Word cloud generation failed: {e}")

    # Sentiment Analysis
    st.markdown("---")
    st.markdown("### üòä Sentiment Analysis")
    try:
        if sentiment_file.exists():
            # Load pre-computed sentiment results
            sentiment_df = pd.read_csv(sentiment_file)

            # Calculate summary statistics from global_sentiment_score
            avg_sentiment = sentiment_df['global_sentiment_score'].mean()
            sentiment_counts = sentiment_df['global_sentiment_class'].value_counts()
            total = len(sentiment_df)

            pos_pct = (sentiment_counts.get('Positive', 0) / total) * 100
            neu_pct = (sentiment_counts.get('Neutral', 0) / total) * 100
            neg_pct = (sentiment_counts.get('Negative', 0) / total) * 100

            # Display metrics
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Avg Sentiment", f"{avg_sentiment:.3f}")
            with col2:
                st.metric("Positive", f"{pos_pct:.1f}%",
                         delta=f"{sentiment_counts.get('Positive', 0)} records",
                         delta_color="off")
            with col3:
                st.metric("Neutral", f"{neu_pct:.1f}%",
                         delta=f"{sentiment_counts.get('Neutral', 0)} records",
                         delta_color="off")
            with col4:
                st.metric("Negative", f"{neg_pct:.1f}%",
                         delta=f"{sentiment_counts.get('Negative', 0)} records",
                         delta_color="off")

            # Show detailed sentiment breakdown
            with st.expander("üìä View Detailed Sentiment by Infrastructure Layer"):
                display_df = sentiment_df[['aspect', 'category', 'global_sentiment_score', 'global_sentiment_class']].copy()
                display_df.columns = ['Aspect', 'Category', 'Sentiment Score', 'Classification']
                st.dataframe(
                    display_df.head(50),
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        "Sentiment Score": st.column_config.NumberColumn(
                            "Sentiment Score",
                            format="%.3f",
                            help="Compound sentiment score (-1 to +1)"
                        )
                    }
                )
        else:
            st.info("Pre-computed sentiment analysis not available.")
    except Exception as e:
        st.warning(f"Sentiment analysis display failed: {e}")

    # Topic Modeling
    st.markdown("---")
    st.markdown("### üéØ Topic Modeling (LDA)")
    try:
        # Load topic keywords from CSV
        topics_keywords_file = analytics_path / "XR_Scalability_Topics.csv"

        if topics_keywords_file.exists():
            # Load pre-computed topics with keywords
            topics_df = pd.read_csv(topics_keywords_file)

            st.markdown("**Infrastructure Layer Topics:**")
            st.markdown("")

            # Display topics with keywords (like other dimensions)
            for idx, row in topics_df.iterrows():
                topic_name = row['topic']
                keywords = row['keywords']

                # Create colored topic boxes with keywords
                st.markdown(f"""
                <div style='background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
                            padding: 15px; border-radius: 8px; border-left: 4px solid {COLORS['accent_teal']};
                            margin: 10px 0;'>
                    <h4 style='margin: 0 0 8px 0; color: {COLORS["primary_blue"]};'>
                        üî∏ {topic_name}
                    </h4>
                    <p style='margin: 0; color: #1a1a1a; font-size: 0.95em;'>
                        <strong>Keywords:</strong> {keywords}
                    </p>
                </div>
                """, unsafe_allow_html=True)

            # Optionally show topic distribution details
            if topics_file.exists():
                with st.expander("üìä View Topic Distribution Across Documents"):
                    lda_df = pd.read_csv(topics_file)
                    topic_cols = [col for col in lda_df.columns if col.startswith('Topic_')]
                    if topic_cols:
                        # Calculate average distribution
                        topic_avgs = {col: lda_df[col].mean() for col in topic_cols}
                        st.markdown("**Average Topic Distribution:**")
                        for col, avg in sorted(topic_avgs.items(), key=lambda x: x[1], reverse=True):
                            st.markdown(f"- {col}: {avg*100:.1f}% average coverage")

                        st.markdown("")
                        st.dataframe(
                            lda_df[topic_cols].head(20),
                            use_container_width=True,
                            column_config={col: st.column_config.NumberColumn(col, format="%.3f") for col in topic_cols}
                        )
        else:
            st.info("Pre-computed topic keywords not available. Run generate_scalability_topic_keywords.py to create them.")
    except Exception as e:
        st.warning(f"Topic modeling display failed: {e}")

else:
    st.info("Limited text data available for analytics")

# ============================================================================
# DATA SOURCES
# ============================================================================

st.markdown("---")
st.markdown("## üìö Verified Data Sources")

st.markdown(f"**{len(sources)} verified URLs** from infrastructure vendors:")

source_categories = {
    "Network Operators": ["nokia", "verizon", "ericsson", "qualcomm"],
    "Cloud Platforms": ["aws", "azure", "microsoft", "google"],
    "Edge Providers": ["cloudflare", "akamai", "vmware"],
    "Infrastructure Tools": ["kubernetes", "nvidia", "mongodb", "okta", "jamf"]
}

for category, keywords in source_categories.items():
    category_sources = [s for s in sources if any(kw in s.lower() for kw in keywords)]
    if category_sources:
        with st.expander(f"üìÅ {category} ({len(category_sources)} sources)"):
            for i, url in enumerate(category_sources, 1):
                st.markdown(f"{i}. [{url}]({url})")

# ============================================================================
# MANAGERIAL IMPLICATIONS
# ============================================================================

st.markdown("---")
st.markdown("## üíº Managerial Implications")

st.markdown("""
**Scalability Requirements:**

- üì° **Network:** 5G/6G connectivity for low-latency streaming (< 20ms)
- üñ•Ô∏è **Edge:** Distributed compute to reduce cloud dependency
- ‚òÅÔ∏è **Cloud:** Elastic rendering capacity for peak demand
- üì± **Device Management:** Enterprise-grade MDM for fleet control
- üîß **Orchestration:** Container-based deployment (Kubernetes)

**Critical Success Factors:**

1. **Hybrid Architecture:** Combine edge + cloud for cost-performance balance
2. **Vendor Partnerships:** Engage with Nokia/Verizon for 5G, AWS/Azure for cloud
3. **Pilot Sizing:** Start with 50-100 devices to validate infrastructure
4. **Bandwidth Planning:** Budget for 10-50 Mbps per active XR device
5. **Monitoring Stack:** Real-time observability for latency and quality metrics

**Cost Considerations:**

- Network: $50-200/device/month (5G connectivity)
- Cloud Rendering: $0.10-1.00/hour per stream
- Edge Infrastructure: $10K-100K capex per edge location
- Device Management: $5-15/device/month
""")

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #6C757D; padding: 20px;'>
    <p><strong>Scalability Analysis</strong></p>
    <p>Part of the Five-Dimension XR Technology Readiness Framework</p>
</div>
""", unsafe_allow_html=True)
